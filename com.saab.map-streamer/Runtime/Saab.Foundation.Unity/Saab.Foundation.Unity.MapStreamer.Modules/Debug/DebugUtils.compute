#pragma kernel CSTransferToTexture

StructuredBuffer<int> Input;
RWTexture2D<float4> Output;

float2 FOV;
float2 Dimensions;

[numthreads(8, 8, 1)]
void CSTransferToTexture(uint3 id : SV_DispatchThreadID)
{    
    Output[id.xy] = 0;
    
    // If outside your texture bounds, return
    if (id.x >= Dimensions.x || id.y >= Dimensions.y)
        return;

    // 1) Convert pixel index => normalized device coords => angle
    float2 uv = (float2) id.xy / (float2) Dimensions.xy; // [0..1]
    float2 ndc = 2.0 * uv - 1.0; // [-1..1]
    
    // 2) Suppose the final image is meant to cover the same fov.x/fov.y 
    float halfFovX = radians(FOV.x * 0.5);
    float halfFovY = radians(FOV.y * 0.5);

    // 3) Reconstruct a direction in camera space:
    // Typically, for a pinhole camera, x = tan(horizontalAngle), etc.
    float xCam = tan(halfFovX) * ndc.x;
    float yCam = tan(halfFovY) * ndc.y;
    float zCam = 1.0;
    float3 dir = normalize(float3(xCam, yCam, zCam));

    // 4) Convert dir => equirectangular coords
    float yawAngle = degrees(atan2(dir.x, dir.z)); // [-fov.x/2.. +fov.x/2]
    float pitchAngle = degrees(asin(dir.y)); // [-fov.y/2.. +fov.y/2]
    float normalizedYaw = saturate((yawAngle + (FOV.x * 0.5)) / FOV.x);
    float normalizedPitch = saturate((pitchAngle + (FOV.y * 0.5)) / FOV.y);

    // 5) Lookup in your culling buffer
    uint yawIndex = (uint) (normalizedYaw * (Dimensions.x - 1));
    uint pitchIndex = (uint) (normalizedPitch * (Dimensions.x - 1));
    uint eqIndex = pitchIndex * Dimensions.x + yawIndex;
    
    uint newDepth = (uint) Input[eqIndex];
    
    if (newDepth < 25000)
        Output[id.xy] = float4(1, 0, 0, 0.2);
    else
        Output[id.xy] = float4(0, 0, 1, 0.2);

}